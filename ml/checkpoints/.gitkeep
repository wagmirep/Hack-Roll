# ml/checkpoints/ - Training Checkpoints
#
# PURPOSE:
#     Store model checkpoints during training.
#     Allows resuming training and selecting best model.
#
# REFERENCED BY:
#     - scripts/train_lora.py - Saves checkpoints here
#     - scripts/export_model.py - Loads best checkpoint
#
# STRUCTURE:
#     checkpoints/
#     ├── checkpoint-500/
#     │   ├── adapter_model.bin
#     │   ├── adapter_config.json
#     │   └── trainer_state.json
#     ├── checkpoint-1000/
#     └── ...
#
# NOTE:
#     Checkpoints are large - add to .gitignore
#     Only keep last N checkpoints (configurable)
