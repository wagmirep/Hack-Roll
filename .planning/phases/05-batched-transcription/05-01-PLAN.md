---
phase: 05-batched-transcription
plan: 01
type: execute
---

<objective>
Transcribe audio chunks as they arrive during recording, caching results for fast post-processing.

Purpose: Eliminate the 60-120 second wait after recording by doing transcription work in parallel with recording.
Output: Background transcription system that caches chunk transcriptions as they're uploaded.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-batched-transcription/05-CONTEXT.md

# Key source files:
@backend/models.py
@backend/routers/sessions.py
@backend/services/transcription.py
@backend/processor.py

**Vision from CONTEXT.md:**
- Transcription happens invisibly during recording
- When user stops, most audio already transcribed
- Only final chunk + diarization needed post-stop
- Target: 5-10 seconds wait (vs 60-120 seconds)

**Current architecture:**
- Mobile uploads 30s chunks during recording
- After stop: concatenate → diarize → transcribe each segment sequentially
- Transcription is 40-85% of total processing time

**Approach:**
- Cache transcriptions per chunk as they arrive
- Fire-and-forget background transcription on upload
- Don't block upload response
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add ChunkTranscription database model</name>
  <files>backend/models.py, backend/alembic/versions/</files>
  <action>
Add ChunkTranscription model to store cached transcription results:

```python
class ChunkTranscription(Base):
    """Cached transcription for uploaded audio chunks"""
    __tablename__ = "chunk_transcriptions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    session_id = Column(UUID(as_uuid=True), ForeignKey("sessions.id"), nullable=False)
    chunk_number = Column(Integer, nullable=False)

    # Transcription results
    raw_text = Column(Text, nullable=True)  # Raw model output
    corrected_text = Column(Text, nullable=True)  # After apply_corrections()
    word_counts = Column(JSONB, nullable=True)  # {word: count} dict

    # Metadata
    duration_seconds = Column(Numeric(10, 3), nullable=True)  # Chunk duration
    transcribed_at = Column(DateTime(timezone=True), nullable=True)
    error_message = Column(Text, nullable=True)  # If transcription failed

    # Constraints
    __table_args__ = (
        Index('ix_chunk_transcriptions_session_chunk', 'session_id', 'chunk_number', unique=True),
    )
```

Create alembic migration. Use `alembic revision --autogenerate -m "add chunk_transcriptions table"` then review and run `alembic upgrade head`.

Import UUID, JSONB from sqlalchemy.dialects.postgresql if not already imported. Add relationship to Session model if desired (optional).
  </action>
  <verify>
- `alembic upgrade head` succeeds
- Table exists: `psql -c "\d chunk_transcriptions"` or check via Python
- Model can be imported: `from models import ChunkTranscription`
  </verify>
  <done>ChunkTranscription model exists, migration applied, table created</done>
</task>

<task type="auto">
  <name>Task 2: Create TranscriptionCache service</name>
  <files>backend/services/transcription_cache.py</files>
  <action>
Create a new service that handles background chunk transcription:

```python
"""
services/transcription_cache.py - Background Chunk Transcription Cache

Transcribes audio chunks as they arrive and caches results.
Used by processor.py to speed up post-recording processing.
"""

import uuid
import logging
import tempfile
import os
from datetime import datetime, timezone
from typing import Optional, Dict, List
from threading import Lock

from sqlalchemy.orm import Session as DBSession

from models import ChunkTranscription, AudioChunk
from database import SessionLocal
from services.transcription import (
    transcribe_audio,
    apply_corrections,
    count_target_words,
)

logger = logging.getLogger(__name__)

# Lock for thread-safe cache operations
_cache_lock = Lock()


async def transcribe_chunk_background(
    session_id: uuid.UUID,
    chunk_number: int,
    audio_bytes: bytes,
    duration_seconds: float
) -> None:
    """
    Transcribe a chunk in the background and cache the result.

    This is fire-and-forget - errors are logged but don't propagate.
    Called after successful chunk upload.
    """
    db = SessionLocal()
    temp_path = None

    try:
        # Check if already transcribed (idempotency)
        existing = db.query(ChunkTranscription).filter(
            ChunkTranscription.session_id == session_id,
            ChunkTranscription.chunk_number == chunk_number
        ).first()

        if existing and existing.transcribed_at:
            logger.debug(f"Chunk {chunk_number} already transcribed, skipping")
            return

        # Save audio to temp file
        temp_path = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
        with open(temp_path, "wb") as f:
            f.write(audio_bytes)

        # Transcribe
        logger.info(f"Background transcribing chunk {chunk_number} for session {session_id}")
        raw_text = transcribe_audio(temp_path)
        corrected_text = apply_corrections(raw_text)
        word_counts = count_target_words(corrected_text)

        # Cache result
        with _cache_lock:
            # Upsert pattern
            cache_entry = existing or ChunkTranscription(
                session_id=session_id,
                chunk_number=chunk_number
            )
            cache_entry.raw_text = raw_text
            cache_entry.corrected_text = corrected_text
            cache_entry.word_counts = word_counts
            cache_entry.duration_seconds = duration_seconds
            cache_entry.transcribed_at = datetime.now(timezone.utc)
            cache_entry.error_message = None

            if not existing:
                db.add(cache_entry)
            db.commit()

        logger.info(f"Cached transcription for chunk {chunk_number}: {len(corrected_text)} chars, {sum(word_counts.values())} target words")

    except Exception as e:
        logger.error(f"Background transcription failed for chunk {chunk_number}: {e}")

        # Record error in cache
        try:
            with _cache_lock:
                cache_entry = db.query(ChunkTranscription).filter(
                    ChunkTranscription.session_id == session_id,
                    ChunkTranscription.chunk_number == chunk_number
                ).first()

                if not cache_entry:
                    cache_entry = ChunkTranscription(
                        session_id=session_id,
                        chunk_number=chunk_number
                    )
                    db.add(cache_entry)

                cache_entry.error_message = str(e)[:500]
                db.commit()
        except Exception:
            pass  # Don't fail on error logging

    finally:
        db.close()
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)


def get_cached_transcriptions(
    db: DBSession,
    session_id: uuid.UUID
) -> Dict[int, ChunkTranscription]:
    """
    Get all cached transcriptions for a session.

    Returns:
        Dict mapping chunk_number -> ChunkTranscription
    """
    results = db.query(ChunkTranscription).filter(
        ChunkTranscription.session_id == session_id,
        ChunkTranscription.transcribed_at.isnot(None)  # Only successful transcriptions
    ).all()

    return {ct.chunk_number: ct for ct in results}


def get_text_for_time_range(
    cached: Dict[int, ChunkTranscription],
    chunks: List[AudioChunk],
    start_time: float,
    end_time: float
) -> Optional[str]:
    """
    Get cached transcription text that covers a time range.

    Used by processor.py to map diarized speaker segments to cached chunk text.

    Args:
        cached: Dict of chunk_number -> ChunkTranscription
        chunks: List of AudioChunk records (for timing info)
        start_time: Segment start in seconds
        end_time: Segment end in seconds

    Returns:
        Concatenated corrected text from overlapping chunks, or None if insufficient coverage
    """
    # Build chunk timing map
    chunk_times = []
    current_time = 0.0

    for chunk in sorted(chunks, key=lambda c: c.chunk_number):
        duration = float(chunk.duration_seconds or 30.0)
        chunk_times.append({
            'number': chunk.chunk_number,
            'start': current_time,
            'end': current_time + duration
        })
        current_time += duration

    # Find overlapping chunks
    overlapping_text = []
    coverage = 0.0
    segment_duration = end_time - start_time

    for ct in chunk_times:
        # Check overlap
        overlap_start = max(ct['start'], start_time)
        overlap_end = min(ct['end'], end_time)

        if overlap_start < overlap_end:
            overlap_duration = overlap_end - overlap_start
            coverage += overlap_duration

            # Get cached text for this chunk
            if ct['number'] in cached:
                text = cached[ct['number']].corrected_text
                if text:
                    overlapping_text.append(text)

    # Require at least 80% coverage to use cache
    if coverage / segment_duration < 0.8:
        return None

    return " ".join(overlapping_text) if overlapping_text else None
```

Key design decisions:
- Fire-and-forget: errors logged but don't fail upload
- Idempotent: won't re-transcribe if already cached
- Thread-safe: uses lock for database operations
- Graceful degradation: processor falls back to direct transcription if cache misses
  </action>
  <verify>
- File exists at backend/services/transcription_cache.py
- Can import: `from services.transcription_cache import transcribe_chunk_background, get_cached_transcriptions`
- No syntax errors: `python -c "from services.transcription_cache import *"`
  </verify>
  <done>TranscriptionCache service created with background transcription and cache lookup functions</done>
</task>

<task type="auto">
  <name>Task 3: Trigger background transcription on chunk upload</name>
  <files>backend/routers/sessions.py</files>
  <action>
Modify the `upload_chunk` endpoint to trigger background transcription after successful upload.

1. Add import at top:
```python
import asyncio
from services.transcription_cache import transcribe_chunk_background
```

2. After the chunk is saved to storage (around line 216 in current code), add:
```python
    # Trigger background transcription (fire-and-forget)
    # Don't await - let it run in background while we return response
    asyncio.create_task(
        transcribe_chunk_background(
            session_id=session_id,
            chunk_number=chunk_number,
            audio_bytes=file_content,  # Need to read file content before this
            duration_seconds=float(duration) if duration else 30.0
        )
    )
```

3. You'll need to read file content before uploading to storage. Modify the flow:
```python
    # Read file content (need for both storage upload and transcription)
    file_content = await file.read()
    await file.seek(0)  # Reset for potential re-read

    # Upload to storage
    storage_path = await storage.upload_chunk(session_id, chunk_number, file)

    # ... existing database operations ...

    # Trigger background transcription
    asyncio.create_task(
        transcribe_chunk_background(
            session_id=session_id,
            chunk_number=chunk_number,
            audio_bytes=file_content,
            duration_seconds=float(duration) if duration else 30.0
        )
    )
```

Important: The upload response should return immediately. Background transcription runs asynchronously. If transcription fails, it's logged but doesn't affect the upload.
  </action>
  <verify>
- Chunk upload still works: test with curl or mobile app
- Background transcription triggers: check logs for "Background transcribing chunk"
- Cache populated: query chunk_transcriptions table after upload
- Upload response time unchanged: should still be fast (~1-2s)
  </verify>
  <done>Chunk upload triggers background transcription, cache populated as chunks arrive</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `alembic upgrade head` succeeds
- [ ] chunk_transcriptions table exists in database
- [ ] Backend starts without import errors
- [ ] Chunk upload works (returns 200)
- [ ] Background transcription logs appear
- [ ] ChunkTranscription records created in database
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No errors on backend startup
- Chunks uploaded during recording are transcribed in background
- Cache entries queryable for use by processor
</success_criteria>

<output>
After completion, create `.planning/phases/05-batched-transcription/05-01-SUMMARY.md`
</output>
